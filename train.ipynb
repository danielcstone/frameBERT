{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from transformers import *\n",
    "from frameBERT.src import utils\n",
    "from frameBERT.src import dataio\n",
    "from frameBERT import frame_parser\n",
    "from frameBERT.src.modeling import BertForJointShallowSemanticParsing\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)   \n",
    "random.seed(0)\n",
    "\n",
    "from torch import autograd\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### loading Korean FrameNet 0.8 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n",
      "\n",
      "### loading Korean FrameNet 1.0 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/disk/frameBERT/model-kfn08/'\n",
    "fnversion = '0.8'\n",
    "language = 'ko'\n",
    "trn8, dev8, tst8 = dataio.load_data(language=language, fnversion=fnversion)\n",
    "\n",
    "model_dir = '/disk/frameBERT/model-kfn10/'\n",
    "fnversion = '1.0'\n",
    "language = 'ko'\n",
    "trn1, dev1, tst1 = dataio.load_data(language=language, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lu(lus):\n",
    "    for i in lus:\n",
    "        if i != '_':\n",
    "            lu = i\n",
    "            break\n",
    "    return lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 총합.n 총합에_이르다.v\n",
      "52 같이하다.v 같다.a\n",
      "66 아름답다.a 가장_아름답다.a\n",
      "80 가락.n 리드미컬하다.a\n",
      "135 소리내다.v 소리.n\n",
      "145 높다.a 위.n\n",
      "154 하다.a 미리.ad\n",
      "162 종종대다.v 종종.ad\n",
      "201 필요.n -야_하다.v\n",
      "208 그러하다.a 그러나.ad\n",
      "227 죽는소리하다.v 죽다.v\n",
      "229 못하다.a 실패하다.v\n",
      "243 있다.a 수_있다.a\n",
      "276 에다.v -에.j\n",
      "291 더하다.a 더.ad\n",
      "293 더하다.a 더.ad\n",
      "294 더하다.a 더.ad\n",
      "296 하다.a -야_하다.v\n",
      "300 하다.a 수_있다.a\n",
      "308 에다.v -에.j\n",
      "324 에다.v 에.j\n",
      "330 에다.v -에.j\n",
      "332 에다.v 에.j\n",
      "335 동안.n 순간.n\n",
      "352 에다.v 국경.n\n",
      "353 에다.v 국경.n\n",
      "363 떠나다.v 운전하다.v\n",
      "365 에다.v 에.j\n",
      "389 에다.v -에.j\n",
      "392 타이핑되다.v 타이핑.n\n",
      "401 고통.n 고통스럽다.a\n",
      "446 에다.v -에.j\n",
      "452 하다.a -려고_하다.v\n",
      "468 수.n 수_있다.a\n",
      "483 젊은이.n 사람.n\n",
      "494 무능력하다.a 무능력.n\n",
      "499 놀라다.v 놀랍다.a\n",
      "504 축하받다.v 받다.v\n",
      "507 가지다.v 갖다.v\n",
      "515 학교.n 학교_선생.n\n",
      "516 생각하다.v 생각.n\n",
      "525 수.n 수_있다.v\n",
      "538 축하받다.v 받다.v\n",
      "539 교육시키다.v 가르치다.v\n",
      "542 더하다.a 더.ad\n",
      "545 같다.a 일종.n\n",
      "553 수.n 수_있다.a\n",
      "555 들다.v 듣다.v\n",
      "569 에다.v -에.j\n",
      "579 알다.v 생각하다.v\n",
      "605 하다.a -야_하다.a\n",
      "606 하다.a -야_하다.a\n",
      "610 불만.n 불만족스럽다.a\n",
      "614 가지다.v 마련하다.v\n",
      "622 있다.a 수_있다.a\n",
      "628 더하다.a 더.ad\n",
      "638 에다.v -에.j\n",
      "648 오래다.a 더_오래되다.a\n",
      "654 있다.a 가지다.v\n",
      "655 보다.v -보다.j\n",
      "672 경향.n 경향이_있다.a\n",
      "676 얻다.v 확보하다.v\n",
      "688 문제.n 이슈.n\n",
      "702 갖다.v 가지다.v\n",
      "712 당선되다.v 당선.v\n",
      "723 기울이다.v 관심을_기울이다.v\n",
      "724 덜하다.a 덜.ad\n",
      "733 에다.v -에.j\n",
      "741 되다.a 수_있다.a\n",
      "750 수.n 수_있다.a\n",
      "780 보이다.v 드러내다.v\n",
      "797 주의.n 주.n\n",
      "798 주의.n 주.n\n",
      "814 주의.n -의.j\n",
      "816 조사하다.v 조사.n\n",
      "819 수.n 수_있다.a\n",
      "826 에다.v 에.j\n",
      "828 수.n 알다.v\n",
      "840 필요하다.a 필요.n\n",
      "841 수.n 수_있다.a\n",
      "842 사고.n 사다.v\n",
      "846 에다.v -에.j\n",
      "860 천명.n 수천.n\n",
      "863 도움.n 도와주다.v\n",
      "872 천명.n 수천.n\n",
      "887 성취감.n 성취감을_주다.v\n",
      "911 사용.n 사용하다.v\n",
      "915 그리다.v 그리고.ad\n",
      "939 영향.n 영향을_주다.v\n",
      "954 되다.a 행동하다.v\n",
      "961 축하받다.v 받다.v\n",
      "964 에다.v -에.j\n",
      "983 같이하다.v 같다.a\n",
      "1001 역할.n 수행하다.v\n",
      "1019 하다.a 만들다.v\n",
      "1028 필요하다.a 필요.n\n",
      "1032 하다.a 수_있다.a\n",
      "1036 하다.a 만들다.v\n",
      "1039 되다.a 치다.v\n",
      "1049 상태.n 실직하다.v\n",
      "1068 에다.v -에.j\n",
      "1089 직업.n 직업이_없다.a\n",
      "1098 많다.a 다양하다.a\n",
      "1108 에다.v -에.j\n",
      "1112 에다.v 에.j\n",
      "1114 에다.v 년.n\n",
      "1119 학대받다.v 학대_받다.v\n",
      "1126 수월하다.a 더_쉽다.a\n",
      "1129 종종대다.v 종종.ad\n",
      "1131 느낌.n 느끼다.v\n",
      "1133 느낌.n 느끼다.v\n",
      "1141 종종대다.v 종종.ad\n",
      "1154 그리다.v 그려지다.v\n",
      "1158 에다.v -에.j\n",
      "1185 믿다.v 엄청나다.a\n",
      "1194 수.n 수_있다.a\n",
      "1209 북쪽.n 북쪽_부분.n\n",
      "1214 에다.v -에.j\n",
      "1227 수준.n 수준_높다.a\n",
      "1238 고기잡이.n 낚시하다.v\n",
      "1246 영향받다.v 영향_받다.v\n",
      "1270 온하다.a 오다.v\n",
      "1272 무역하다.v 무역.n\n",
      "1278 온하다.a 오다.v\n",
      "1281 시대.n 암흑시대.n\n",
      "1306 존경받다.v 존중되다.v\n",
      "1307 에다.v 에.j\n",
      "1328 에다.v -에.j\n",
      "1332 마침하다.a 마침내.ad\n",
      "1334 주시당하다.v 벌을_주다.v\n",
      "1344 알리다.v 알려지다.v\n",
      "1362 에다.v -에.j\n",
      "1374 가져오다.v 영향.n\n",
      "1386 지역.n 시골_지역.n\n",
      "1400 보내다.v 보내지다.v\n",
      "1418 없다.a 아무도.ad\n",
      "1435 에다.v 년.n\n",
      "1460 그러하다.a 그러나.ad\n",
      "1469 되다.a 오다.v\n",
      "1482 성공.n 성공적이지_못하다.a\n",
      "1485 하다.a 역할을_하다.v\n",
      "1520 하다.a 시도하다.v\n",
      "1550 세기.n 수_세기.n\n",
      "1573 주시당하다.v 주다.v\n",
      "1574 주시당하다.v 주다.v\n",
      "1575 기반.n 사회_기반_시설.n\n",
      "1580 하다.a 만들다.v\n",
      "1608 축하받다.v 받다.v\n",
      "1674 방어되다.v 보호되다.v\n",
      "1726 십자가형.n 십자가_처형.n\n",
      "1747 이루어지다.v 일어나다.v\n",
      "1769 만들다.v 만들어지다.v\n",
      "1787 통제하다.v 통제.n\n",
      "1794 죽는소리하다.v 죽다.v\n",
      "1813 멈추다.v 중단시키다.v\n",
      "1851 문화공연.n 문화원.n\n",
      "1856 시대.n 선사시대.n\n",
      "1874 말하다.v 말해주다.v\n",
      "1885 에다.v 결국.n\n",
      "1909 수.n 수_없다.a\n",
      "1916 에다.v -에.j\n",
      "1917 에다.v -에.j\n",
      "1920 에다.v -에.j\n",
      "1927 좋다.a 유망하다.a\n",
      "1928 에다.v -에.j\n",
      "1987 에다.v -에.j\n",
      "2012 지어내다.v 건설되다.v\n",
      "2028 나서다.v 그러고_나다.v\n",
      "2031 기관.n 입법기관.n\n",
      "2035 에다.v -에.j\n",
      "2043 주시당하다.v 주다.v\n",
      "2055 에다.v 에.j\n",
      "2056 하다.a 역할을_하다.v\n",
      "2064 만들다.v 구축했다.v\n",
      "2069 기관.n 입법_기관.n\n",
      "2072 없다.a 수_있다.a\n",
      "2084 에다.v -에.j\n",
      "2092 에다.v -에.j\n",
      "2094 에다.v -에.j\n",
      "2097 에다.v 에.j\n",
      "2100 에다.v -에.j\n",
      "2104 에다.v -에.j\n",
      "2108 에다.v -에.j\n",
      "2117 에다.v 에.j\n",
      "2118 에다.v -에.j\n",
      "2130 일부.n 어떤.m\n",
      "2146 요청받다.v 요청_받다.v\n",
      "2172 얻다.v 맞바꾸다.v\n",
      "2174 건물.n 철거.n\n",
      "2190 더하다.a 더.ad\n",
      "2204 하다.a -야_하다.v\n",
      "2208 특징지.n 특징짓다.v\n",
      "2227 상대평가.n 비길_데가_없다.a\n",
      "2249 축하받다.v 받다.v\n",
      "2258 만들다.v 건설되다.v\n",
      "2260 에다.v -에.j\n",
      "2263 온하다.a 출신.n\n",
      "2274 때.n -까지.j\n",
      "2275 에다.v 에.j\n",
      "2337 에다.v 에.j\n",
      "2343 수.n 수백.n\n",
      "2363 식민지.n 개척자.n\n",
      "2378 에다.v -에.j\n",
      "2393 들.n 말하다.v\n",
      "2411 즐기다.v 향유되다.v\n",
      "2434 주시당하다.v 제공하다.v\n",
      "2450 수.n 수_있다.a\n",
      "2454 하다.a -야_하다.v\n",
      "2456 오래다.a 오래.ad\n",
      "2457 이름나다.v 명성을_얻다.v\n",
      "2464 에다.v 에.j\n",
      "2476 수.n 수_있다.a\n",
      "2478 들다.v 듣다.v\n",
      "2484 울려오다.v 울려나오다.v\n",
      "2494 수.n 수도.n\n",
      "2522 사람.n 아일랜드_사람.n\n",
      "2530 걸다.a 걷다.v\n",
      "2545 기분.n 기분_좋다.a\n",
      "2549 멀리하다.v 북쪽.n\n",
      "2591 하다.a -야_하다.v\n",
      "2596 말아먹다.v -야_하다.a\n",
      "2623 마침하다.a 마침내.ad\n",
      "2654 지금.n 더_이상.ad\n",
      "2668 깜짝하다.v 깜짝.ad\n",
      "2716 에다.v -에.j\n",
      "2722 비탄.n 비통해_하다.v\n",
      "2727 되다.a 얼마.ad\n",
      "2728 되다.a 얼마.ad\n",
      "2729 되다.a 얼마.ad\n",
      "2742 보이다.v 보여주다.v\n",
      "2745 같이하다.v 같다.a\n",
      "2750 예술가.n 엉터리_예술가.n\n",
      "2768 하다.a 유지하다.v\n",
      "2781 쓰다.a 이용하다.v\n",
      "2789 에다.v -에.j\n",
      "2793 너무하다.a 너무.ad\n",
      "2794 필요하다.a 요구되다.v\n",
      "2796 잘못되다.v 잘못된_방향으로_나가게_하다.v\n",
      "2797 필요하다.a 필요.n\n",
      "2798 머물다.v 남다.v\n",
      "2817 되다.a 때.n\n",
      "2832 에다.v 에.j\n",
      "2841 에다.v -에.j\n",
      "2862 에다.v -에는.j\n",
      "2867 의하다.v -에.j\n",
      "2868 짓다.v 지어지다.v\n",
      "2869 수.n 수_있다.a\n",
      "2881 에다.v -에.j\n",
      "2888 주의깊다.a 주의.n\n",
      "2889 에다.v -에.j\n",
      "2895 구불텅하다.a 구불하다.a\n",
      "2904 있다.a 가지다.v\n",
      "2908 에다.v -에.j\n",
      "2911 걸다.a 걷다.v\n",
      "2926 에다.v -에.j\n",
      "2931 에다.v -에는.j\n",
      "2937 에다.v 에는.j\n",
      "2938 수.n 수_있다.a\n",
      "2941 걸다.a 걷다.v\n",
      "2944 인력거.n 있다.a\n",
      "2947 까지다.a -까지.j\n",
      "2957 에다.v 에.j\n",
      "2975 더하다.a 더.ad\n",
      "2977 걸다.a 걷다.v\n",
      "2994 에다.v -에.j\n",
      "2999 에다.v 에.j\n",
      "3051 마다하다.v -마다.j\n",
      "3052 오르다.v 등반하다.v\n",
      "3065 에다.v -에.j\n",
      "3072 지배당하다.v 당국.n\n",
      "3095 즐겁다.a 즐겁게_뛰놀다.v\n",
      "3109 하다.a 수_있다.a\n",
      "3116 자.n 줄이다.v\n",
      "3117 에다.v -에.j\n",
      "3172 비난받다.v 비난_받다.v\n",
      "3183 더하다.a 더.ad\n",
      "3208 이.n 줄짓다.v\n",
      "3216 만들다.v 조성되다.v\n",
      "3226 에다.v 에.j\n",
      "3227 에다.v -에.j\n",
      "3236 판단하다.v 시도하다.v\n",
      "3237 하고많다.a 시도하다.v\n",
      "3282 수.n 수_있다.a\n",
      "3285 하다.a 수_있다.a\n",
      "3289 주시당하다.v 주다.v\n",
      "3290 주시당하다.v 주다.v\n",
      "3295 주시당하다.v 주다.v\n",
      "3297 설명하다.v 기술하다.v\n",
      "3315 찌그리다.v 찌그러뜨리다.v\n",
      "3320 죽는소리하다.v 죽다.v\n",
      "3353 수.n 수_있다.a\n",
      "3363 보도.n 전해지다.v\n",
      "3367 지키다.v 준수하다.v\n",
      "3412 지다.v 짓다.v\n",
      "3422 수.n 수_있다.a\n",
      "3427 수.n 수_있다.a\n",
      "3440 의하다.v 전해진_바에_의하다.mwe\n",
      "3529 믿다.v -고_믿다.v\n",
      "3535 있다.a 가지다.v\n",
      "3560 제조.n 제조하다.v\n",
      "3564 주시당하다.v 주.n\n",
      "3573 더하다.a 더.ad\n",
      "3583 생화학.n 생물학무기.n\n",
      "3585 달리하다.v 달리.ad\n",
      "3590 기술.n 비결.n\n",
      "3595 대량살상.n 대량_살상_무기.n\n",
      "3596 하다.a -도록_하다.v\n",
      "3601 파괴.n 대량_파괴_무기.n\n",
      "3603 파괴.n 대량_파괴_무기.n\n",
      "3626 수.n 수_있다.a\n",
      "3637 대량살상.n 대량_살상_무기.n\n",
      "3659 안다.v 알다.v\n",
      "3691 믿다.v -고_믿다.v\n",
      "3705 가지다.v 보유하다.v\n",
      "3711 있다.a 가지다.v\n",
      "3713 가지다.v 보유하다.v\n",
      "3716 하다.a 시도하다.v\n",
      "3717 가지다.v 보유하다.v\n",
      "3725 가지다.v 갖다.v\n",
      "3728 경기대회.n 회복.n\n",
      "3729 경기대회.n 회복.n\n",
      "3730 경기대회.n 회복.n\n",
      "3750 보고하다.v 전해진_바에_의하다.mwe\n",
      "3752 생화학.n 생물학무기.n\n",
      "3794 에다.v -에.j\n",
      "3804 대하다.v -에.j\n",
      "3805 수.n 수도.n\n",
      "3808 안되다.a 적다.a\n",
      "3820 말하다.v 보고.n\n",
      "3843 필요.n 필요하다.a\n",
      "3853 대량살상.n 대량_살상_무기.n\n",
      "3869 수.n 수도.n\n",
      "3887 문제.n 이슈.n\n",
      "3898 요청받다.v 요청하다.v\n",
      "3902 하다.a -야_하다.v\n",
      "3906 치료.n 치료_가능하다.a\n",
      "3907 죽는소리하다.v 죽다.v\n",
      "3922 대량살상.n 대량_살상_무기.n\n",
      "3930 거래.n 해결하다.v\n",
      "3931 하다.a 수_있다.a\n",
      "3938 수.n 수_있다.a\n",
      "3945 에다.v 에.j\n",
      "3965 돌리다.v 탓.n\n",
      "3973 죽는소리하다.v 죽다.v\n",
      "3987 문제.n 이슈.n\n",
      "3992 에다.v -에.j\n",
      "3995 상처주다.v 상처.n\n",
      "4010 주목.n 주목하다.v\n",
      "4011 포함하다.v 포함되다.v\n",
      "4033 풍요롭다.a 더_풍요롭다.a\n",
      "4038 전화.n 전화하다.v\n",
      "4054 아프다.a 아프게_하다.v\n",
      "4055 독성.n 독성이_있다.a\n",
      "4058 행위.n 방해_행위.n\n",
      "4059 행위.n 사보타주.n\n",
      "4060 행위.n 방해_행위.n\n",
      "4074 갖다.v 구비하다.v\n",
      "4090 가지다.v 보유하다.v\n",
      "4113 에다.v 에.j\n",
      "4128 빨리다.v 빨리.ad\n",
      "4134 하다.a -야_하다.v\n",
      "4149 만들다.v 짓다.v\n",
      "4151 되다.a -야_하다.v\n",
      "4165 하다.a -야_하다.v\n",
      "4173 취하하다.v 적용하다.v\n",
      "4174 하다.a -야_하다.a\n",
      "4179 되다.a 안되다.a\n",
      "4180 속하다.v 있다.v\n",
      "4185 하다.a -야_하다.a\n",
      "4196 수.n 수_있다.a\n",
      "4198 하다.a -야_하다.a\n",
      "4204 따르다.v 준수하다.v\n",
      "4212 에다.v -에.j\n",
      "4214 에다.v 에.j\n",
      "4216 에다.v 에.j\n",
      "4217 하다.a -야_하다.v\n",
      "4240 역할.n 역할을_하다.v\n",
      "4245 거래하다.v 거래.n\n",
      "4259 하다.a -야_하다.v\n",
      "4270 하다.a -야_하다.v\n",
      "4278 하다.a -야_하다.a\n",
      "4285 가지다.v 보유하다.v\n",
      "4286 을러메다.v -을.j\n",
      "4287 하다.a 가지다.v\n",
      "4290 수.n 수_있다.a\n",
      "4292 인근지역.n 인근_지역.n\n",
      "4293 지역.n 인접_지역.n\n",
      "4315 하다.a -야_하다.v\n",
      "4320 하다.a -야_하다.v\n",
      "4323 사항.n 필요.n\n",
      "4354 하다.a 유지하다.v\n",
      "4360 단신.n 회보.n\n",
      "4422 수.n 수_있다.a\n",
      "4433 수도.n 수_있다.a\n",
      "4438 수도.n 수_있다.a\n",
      "4440 하다.a -야_하다.v\n",
      "4457 수.n 수_있다.a\n",
      "4474 하다.a -야_하다.v\n",
      "4483 수.n 수_있다.a\n",
      "4518 지키다.v 따르다.v\n",
      "4534 경향.n 경향이_있다.a\n",
      "4562 심기일전하다.v 전하다.v\n",
      "4569 예상되다.v 추정되다.v\n",
      "4585 사업하다.v 사업.n\n",
      "4590 지역.n 구역.n\n",
      "4594 하다.a 만들다.v\n",
      "4602 못하다.a 실패하다.v\n",
      "4630 오래다.a 오래.ad\n",
      "4631 방해받다.v 방해.n\n",
      "4640 믿다.v -고_믿다.v\n",
      "4644 질문하다.v 요청하다.v\n",
      "4660 하다.a 수_있다.a\n",
      "4663 같다.a 수_있다.a\n",
      "4668 관심갖다.v 우려하다.v\n",
      "4685 안다.v 알다.v\n",
      "4697 에다.v -에.j\n",
      "4698 이야기되다.v 논의하다.v\n",
      "4700 보건.n 위생.n\n",
      "4703 많다.a 더_많다.a\n",
      "4705 공무원.n 연방.n\n",
      "4768 하다.a -야_하다.v\n",
      "4775 하다.a -야_하다.v\n",
      "4790 하다.a -야_하다.a\n",
      "4800 같다.a 들리다.v\n",
      "4811 알다싶.n 알다시피.ad\n",
      "4815 지내다.v 괜찮다.a\n",
      "4831 때.n -까지.j\n",
      "4845 들다.v 듣다.v\n",
      "4847 축하받다.v 받다.v\n",
      "4886 첫째가다.v 첫째.n\n",
      "4905 더하다.a 더.ad\n",
      "4911 하다.a 만들다.v\n",
      "4936 불시검문하다.v 검문하다.v\n",
      "4953 들다.v 듣다.v\n",
      "4972 마다하다.v -마다.j\n",
      "4997 형제.n 형제단.n\n",
      "5000 형제.n 형제단.n\n",
      "5006 형제.n 무슬림_형제단.n\n",
      "5011 더하다.a 더.ad\n",
      "5028 하다.a -야_하다.a\n",
      "5032 강력하다.a 더_강력하다.a\n",
      "5037 더하다.a 더.ad\n",
      "5042 안다.v 알다.v\n",
      "5046 상향조정하다.v 조정하다.v\n",
      "5063 엉망.n 망가뜨리다.v\n",
      "5068 에다.v 에.j\n",
      "5080 저어.n 알다.v\n",
      "5081 저어.n 알다.v\n",
      "5084 저어.n 알다.v\n",
      "5093 에다.v -에.j\n",
      "5094 저어.n 알다.v\n",
      "5095 가지다.v 갖다.v\n",
      "5096 안다.v 알다.v\n",
      "5102 어.n 알다.v\n",
      "5103 더하다.a 더.ad\n",
      "5106 저어.n 알다.v\n",
      "5107 저어.n 알다.v\n",
      "5108 하다.a -야_하다.v\n",
      "5111 사건.n 사례.n\n",
      "5117 들다.v 듣다.v\n",
      "5126 들다.v 듣다.v\n",
      "5149 알다.v 알다시피.ad\n",
      "5150 알다.v 알다시피.ad\n",
      "5154 축하받다.v 만하다.a\n",
      "5168 관장하다.v 관할하다.v\n",
      "5173 알다.v 알다시피.ad\n",
      "5176 삼다.v 삼백.n\n",
      "5180 들다.v 듣다.v\n",
      "5183 있다.a 가지다.v\n",
      "5189 있다.a 속하다.a\n",
      "5194 어.n 알다.v\n",
      "5202 있다.a 수_있다.a\n",
      "5204 에다.v 에.j\n",
      "5205 있다.a 안.n\n",
      "5208 있다.a 안.n\n",
      "5209 에다.v -에.j\n",
      "5211 하다.a 야_하다.v\n",
      "5213 에다.v -에.j\n",
      "5217 가다.v 갈다.v\n",
      "5218 에다.v 에.j\n",
      "5220 들다.v 듣다.v\n",
      "5232 수.n 수_있다.a\n",
      "5234 하다.a 필요하다.a\n",
      "5262 만들다.v 제조하다.v\n",
      "5269 온하다.a 오다.v\n",
      "5271 초청받다.v 초청_받다.v\n",
      "5273 축하받다.v 받다.v\n",
      "5275 축하받다.v 받다.v\n",
      "5278 알다.v 안다.v\n",
      "5279 종종대다.v 종종.ad\n",
      "5289 죽는소리하다.v 죽다.v\n",
      "5295 성명.n 주장하다.v\n",
      "5319 에다.v 에.j\n",
      "5339 기업결합.n 카르텔.n\n",
      "5361 관심갖다.v 관심_갖다.v\n",
      "5364 생물학무기.n 생물_무기.n\n",
      "5373 만들다.v 생산하다.v\n",
      "5374 얼마되다.v 쉽다.a\n",
      "5381 하다.a -야_하다.v\n",
      "5391 생물학무기.n 생물학_테러.n\n",
      "5396 테러리즘.n 생물_테러리스트.n\n",
      "5400 테러리즘.n 생물_테러리즘.n\n",
      "5411 개발하다.v 발전시키다.v\n",
      "5422 생물학무기.n 생물_무기.n\n",
      "5438 독성.n 유독하다.a\n",
      "5440 수.n 수_있다.a\n",
      "5465 수.n 가능하다.a\n",
      "5472 백만.n 수백만.n\n",
      "5479 수.n 수_있다.a\n",
      "5481 보이다.v 증명하다.v\n",
      "5606 활발하다.a 활동적이다.a\n",
      "5610 활발하다.a 활동적이다.a\n",
      "5697 탄도미사일.n 탄도_미사일.n\n",
      "5723 탄도미사일.n 탄도_미사일.n\n",
      "5726 수.n 수_있다.a\n",
      "5744 수.n 수_있다.a\n",
      "5770 에다.v -에.j\n",
      "5779 보고하다.v -에.j\n",
      "5781 도운.n 돕다.v\n",
      "5803 생물학무기.n 생물_무기.n\n",
      "5822 겨자.n 겨자_가스.n\n",
      "5827 수.n 수_있다.a\n",
      "5841 탄도미사일.n 탄도_미사일.n\n",
      "5846 수.n 도달하다.a\n",
      "5854 문제.n 질문.n\n",
      "5857 알리다.v 알려지다.v\n",
      "5881 탄도미사일.n 탄도_미사일.n\n",
      "5905 탄도미사일.n 탄도_미사일.n\n",
      "5922 가지다.v 갖다.v\n",
      "5929 생명공학.n 생명_공학.n\n",
      "5931 가지다.v 보유하다.v\n",
      "5943 생명공학.n 생명_공학.n\n",
      "5944 생명공학.n 생명_공학.n\n",
      "5968 원인.n 원인이_되다.v\n",
      "5985 만들다.v 생산하다.v\n",
      "6014 틀리다.v 반증하다.v\n",
      "6026 가지다.v 보유하다.v\n",
      "6040 되다.a 가지다.v\n",
      "6049 영향.n 영향을_미치다.v\n",
      "6050 영향.n 영향을_주다.v\n",
      "6126 수.n 수_있다.a\n",
      "6141 주장하다.v 주장에_의하다.mwe\n",
      "6163 보이.n 보이다.v\n",
      "6187 못하다.a 실패하다.v\n",
      "6194 하다.a 부르다.v\n",
      "6204 중이.n 개발중.n\n",
      "6224 의하다.v 전해진_바에_의하다.mwe\n",
      "6267 능력있다.a 능력.n\n",
      "6273 주장하다.v 주장.n\n",
      "6286 추구하다.v 추진하다.v\n",
      "6296 계속하다.v 유지하다.v\n",
      "6320 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "6322 주시당하다.v 주로.ad\n",
      "6336 겨자.n 겨자_가스.n\n",
      "6338 제조.n 제조하다.v\n",
      "6339 제조.n 만들다.v\n",
      "6397 엄격하다.a 더_엄격하다.a\n",
      "6402 가지다.v 보유하다.v\n",
      "6428 보이다.v 비추다.v\n",
      "6495 알다.v 알게_되다.v\n",
      "6528 하다.a 주장하다.v\n",
      "6537 원자폭탄.n 핵무기.n\n",
      "6563 믿다.v -고_믿다.v\n",
      "6569 수.n 수_있다.a\n",
      "6586 이다.a 잇다.v\n",
      "6593 같지않다.a 것_같지_않다.a\n",
      "6600 보이다.v 입증하다.v\n",
      "6612 여지.n 의심의_여지.n\n",
      "6655 없다.a 가지다.v\n",
      "6672 탄도미사일.n 탄도_미사일.n\n",
      "6688 탄도미사일.n 탄도_미사일.n\n",
      "6691 미사일.n 스커드-B_미사일.n\n",
      "6716 공급받다.v 공급_받다.v\n",
      "6733 탄도미사일.n 탄도_미사일.n\n",
      "6762 예상되다.v 추정되다.v\n",
      "6816 여기다.v 판단되다.v\n",
      "6866 축하받다.v 받다.v\n",
      "6875 협정.n 협력.n\n",
      "6880 전문지식.n 전문_지식.n\n",
      "6910 파괴력.n 대량_파괴_무기.n\n",
      "6923 수.n 수_있다.a\n",
      "6924 탄도미사일.n 탄도_미사일.n\n",
      "6931 대단하다.a 중요하다.a\n",
      "6935 탄도미사일.n 탄도_미사일.n\n",
      "6941 업그레이드하다.v 착수하다.v\n",
      "6947 구매하다.v 구매.n\n",
      "6950 여기다.v 판단되다.v\n",
      "6953 여기다.v 간주되다.v\n",
      "6956 만들다.v 조직되다.v\n",
      "6966 제거하다.v 제거.n\n",
      "7014 탄로.n 드러나다.v\n",
      "7067 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "7071 가공.n 재가공.n\n",
      "7075 밝히다.v 폭로되다.v\n",
      "7101 여기다.v 간주되다.v\n",
      "7134 무기.n 핵_무기.n\n",
      "7151 원심.n 원심_분리기.n\n",
      "7225 원심.n 원심_분리기.n\n",
      "7248 취하하다.v 취하다.v\n",
      "7261 달리하다.v 다르다.a\n",
      "7266 같지않다.a 것_같지_않다.a\n",
      "7276 이루어지다.v 시행하다.v\n",
      "7281 질책받다.v 질책_받다.v\n",
      "7310 가지다.v 갖추다.v\n",
      "7315 원심.n 원심분리기.n\n",
      "7327 만들다.v 만들어지다.v\n",
      "7390 기반.n 기반_시설.n\n",
      "7395 알리다.v 알려지다.v\n",
      "7397 옮기다.v 옮겨지다.v\n",
      "7404 알리다.v 알려지다.v\n",
      "7414 에다.v 에.j\n",
      "7455 내오다.v 안.n\n",
      "7457 발견하다.v 찾다.v\n",
      "7462 원심.n 원심분리기.n\n",
      "7471 까지다.a -으로.j\n",
      "7515 도움받다.v 지원받다.v\n",
      "7516 도움받다.v 도움.n\n",
      "7519 파괴.n 대량_파괴_무기.n\n",
      "7521 관련되다.v 관하다.v\n",
      "7525 미사일.n 스커드-B_미사일.n\n",
      "7530 심기일전하다.v 전하는_바에_의하다.mwe\n",
      "7534 의하다.v 전해진_바에_의하다.mwe\n",
      "7542 심기일전하다.v 전해지다.v\n",
      "7548 관심.n 우려.n\n",
      "7570 하다.a 믿다.v\n",
      "7601 포.n 대포.n\n",
      "7604 밀리다.v 밀리미터.n\n",
      "7620 수.n 수_있다.a\n",
      "7640 역점.n 강조하다.v\n",
      "7656 평가하다.v 평가.n\n",
      "7678 포.n 대포.n\n",
      "7680 쉬다.v 쉽다.a\n",
      "7684 천문.n 수천.n\n",
      "7685 포.n 대포.n\n",
      "7691 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "7702 곳.n 위치.n\n",
      "7708 천문.n 수백.n\n",
      "7710 포.n 대포.n\n",
      "7711 미사일.n 스커드-C_미사일.n\n",
      "7713 포.n 대포.n\n",
      "7715 수.n 수_있다.a\n",
      "7731 하다.a -게_하다.a\n",
      "7733 수.n 수_있다.a\n",
      "7759 하다.a 수_있다.a\n",
      "7837 내.n 말.n\n",
      "7851 명확하다.a 상태이다.a\n",
      "7852 명확하다.a 남다.v\n",
      "7858 명확하다.a 불명확하다.a\n",
      "7863 수.n 수_있다.a\n",
      "7872 중점.n 강조하다.v\n",
      "7879 보고하다.v 보고서.n\n",
      "7903 중단.n 일시적_중단.n\n",
      "7928 의심받다.v 의심.n\n",
      "7939 기반.n 기반_시설.n\n",
      "7944 비밀.n 기밀이_아닌.m\n",
      "7969 알리다.v 알려지다.v\n",
      "7971 수.n 수_있다.a\n",
      "7981 수.n 수_있다.a\n",
      "7982 필요.n 요구하다.v\n",
      "7987 수도.n 수_있다.a\n",
      "8002 알리다.v 알려지다.v\n",
      "8003 원자폭탄.n 원자_폭탄.n\n",
      "8026 말.n 성명.n\n",
      "8028 확인하다.v 공시하다.v\n",
      "8052 나오다.v 잇따르다.v\n",
      "8079 있다.a 재처리하다.v\n",
      "8103 밝히다.v 밝혀지다.v\n",
      "8106 원심.n 원심분리기.n\n",
      "8123 사용되다.v 사용하다.v\n",
      "8131 믿다.v -라고_믿다.v\n",
      "8283 시작하다.v 시작되다.v\n",
      "8301 하다.a -야_하다.v\n",
      "8316 역할.n 능력.n\n",
      "8326 만족하다.v 불만족하다.v\n",
      "8368 수.n 수_있다.a\n",
      "8374 대량.n 대량_파괴_무기.n\n",
      "8402 많다.a 크다.a\n",
      "8439 것.n 수_있다.a\n",
      "8456 방해받다.v 방해.n\n",
      "8462 탄도미사일.n 탄도_미사일.n\n",
      "8465 개발되다.v 개발.n\n",
      "8475 탄도미사일.n 탄도_미사일.n\n",
      "8482 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "8500 낳다.v -게_하다.a\n",
      "8510 탄도미사일.n 탄도_미사일.n\n",
      "8576 제조.n 제조하다.v\n",
      "8590 생물학무기.n 생물_무기.n\n",
      "8605 만들다.v 구축하다.v\n",
      "8636 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "8639 기반.n 기반_시설.n\n",
      "8713 폭넓다.a 더_폭넓다.a\n",
      "8723 훈련받다.v 훈련_받다.v\n",
      "8738 관심.n 관심_가지다.v\n",
      "8776 에다.v 에.j\n",
      "8790 더하다.a 더.ad\n",
      "8823 에다.v 에는.j\n",
      "8835 같이하다.v 같다.a\n",
      "8841 파괴.n 대량_파괴_무기.n\n",
      "8849 파괴.n 대량_파괴_무기.n\n",
      "8856 파괴.n 대량_파괴_무기.n\n",
      "8857 주장되다.v 주장하다.v\n",
      "8871 생물학무기.n 생물_무기.n\n",
      "8872 생물학무기.n 생물_무기.n\n",
      "8920 무기.n 화학_무기.n\n",
      "8954 필요하다.a 필요.n\n",
      "8956 말하다.v 제안하다.v\n",
      "8958 더하다.a 더.ad\n",
      "8959 주시당하다.v 주다.v\n",
      "8994 주시당하다.v 주.n\n",
      "9037 대량살상.n 대량_살상_무기.n\n",
      "9044 테러리즘.n 생물_테러리즘.n\n",
      "9051 없다.a 가지다.v\n",
      "9080 비난받다.v 비난_받다.v\n",
      "9119 목적.n 의도되다.v\n",
      "9137 축하받다.v 받다.v\n",
      "9141 축하받다.v 받다.v\n",
      "9158 가지다.v 보유하다.v\n",
      "9170 중.n 곳.n\n",
      "9176 겨자.n 겨자가스.n\n",
      "9183 이르다.a 포함하다.v\n",
      "9232 위태롭다.a 위태롭게_만들다.v\n",
      "9244 무기.n 화학_무기.n\n",
      "9272 생물학무기.n 생물_무기.n\n",
      "9275 하다.a 하다.v\n",
      "9283 속하다.v 소속되다.v\n",
      "9290 개발.n 개발하다.v\n",
      "9291 제조.n 제조하다.v\n",
      "9296 무기.n 화학_무기.n\n",
      "9306 실행.n 수행하다.v\n",
      "9310 터뜨리다.v 설치하다.v\n",
      "9352 원심.n 원심분리기.n\n",
      "9353 의하다.v -에.j\n",
      "9362 못하다.a 막다.v\n",
      "9374 지방출신.n 지방.n\n",
      "9379 만들다.v 제조되다.v\n",
      "9390 플라스틱.n 플라스틱_폭탄.n\n",
      "9392 에다.v 에.j\n",
      "9397 이야기하다.v 이야기.n\n",
      "9398 삐걱거리다.v 소리.n\n",
      "9399 들다.v 듣다.v\n",
      "9440 수.n 수_있다.a\n",
      "9452 수.n 수_있다.a\n",
      "9453 탄도미사일.n 탄도_미사일.n\n",
      "9462 하다.a 시도하다.v\n",
      "9475 수.n 수_있다.a\n",
      "9483 협상하다.v 협상.n\n",
      "9500 결정하다.a 핵심.n\n",
      "9521 믿다.v 믿어지다.v\n",
      "9526 가지다.v 보유하다.v\n",
      "9545 만들다.v 구축하다.v\n",
      "9565 생물학무기.n 생물_무기.n\n",
      "9579 가지다.v 보유하다.v\n",
      "9588 기반.n 기반_시설.n\n",
      "9648 가지다.v 갖다.v\n",
      "9649 보고하다.v 보고서.n\n",
      "9656 요청하다.v 도움.n\n",
      "9684 심기일전하다.v 전하다.v\n",
      "9708 중이.n 협상.n\n",
      "9714 보고하다.v 보고서.n\n",
      "9723 요청하다.v 돕다.v\n",
      "9728 지다.v 짓다.v\n",
      "9737 하다.a 말하다.v\n",
      "9754 알리다.v 통보하다.v\n",
      "9772 축하받다.v 받다.v\n",
      "9781 심기일전하다.v 전해지는_바에_의하다.mwe\n",
      "9812 심기일전하다.v 전해지다.v\n",
      "9880 보고되다.v 보고하다.v\n",
      "9916 여기다.v 간주하다.v\n",
      "9918 차이.n 의견_차이.n\n",
      "9939 축하받다.v 받다.v\n",
      "9943 기술.n 비결.n\n",
      "9948 갖다.v 가지다.v\n",
      "10003 심기일전하다.v 전하다.v\n",
      "10017 들다.v 듣다.v\n",
      "10043 거래.n 불법_거래자.n\n",
      "10058 없다.a 수_있다.a\n",
      "10064 나가다.v 나가버리다.v\n",
      "10069 없다.a 수_없다.a\n",
      "10079 달리하다.v 달리.ad\n",
      "10086 만들다.v 만들어지다.v\n",
      "10089 문제.n 이야기.n\n",
      "10108 생각.n 생각하다.v\n",
      "10123 깊숙하다.a 뒤.n\n",
      "10132 봐주다.v 보다.v\n",
      "10134 알다.v 알아가다.v\n",
      "10135 취하하다.v 취하다.v\n",
      "10138 더하다.a 더.ad\n",
      "10146 곧바르다.a 곧바로.ad\n",
      "10161 만들다.v 만들어주다.v\n",
      "10192 축하받다.v 받다.v\n",
      "10232 들다.v -아보다.e\n",
      "10241 마신.n 마시다.v\n",
      "10256 오르락내리락하다.v 오르락내리락.ad\n",
      "10293 들다.v 듣다.v\n",
      "10294 들다.v 듣다.v\n",
      "10307 늘어놓다.v 푸념.n\n",
      "10309 있다.a 수_있다.a\n",
      "10344 하다.a 말하다.v\n",
      "10370 함께하다.v 함께.ad\n",
      "10380 오래다.a 계속.ad\n",
      "10389 풀이.n 질리다.a\n",
      "10409 안.n 방안.n\n",
      "10422 잠자다.v 잠자코.ad\n",
      "10450 따르다.v 행진하다.v\n",
      "10475 말.n 말을_걸다.v\n",
      "10477 손.n 손을_내밀다.v\n",
      "10485 화가.n 초조하다.a\n",
      "10503 얼굴.n 빨갛다.a\n",
      "10550 깜짝하다.v 놀라다.v\n",
      "10581 하다.a 어이없다.a\n",
      "10598 얻다.v 얻어지다.v\n",
      "10607 축하받다.v 받아_챙기다.v\n",
      "10620 동거이.n 동거인.n\n",
      "10623 않다.a 시작하다.v\n",
      "10640 걸다.a 걷다.v\n",
      "10644 긴하다.a 길다.a\n",
      "10667 눈.n 눈뜨다.v\n",
      "10671 들다.v 듣다.v\n",
      "10673 들다.v 듣다.v\n",
      "10700 모욕당하다.v 모욕.n\n",
      "10704 공포.n 떨다.v\n",
      "10706 진정하다.v 진정하다.a\n",
      "10708 들다.v 들어보다.v\n",
      "10726 급격하다.a 격감하다.v\n",
      "10741 쉬다.v 쉽다.a\n",
      "10750 만들다.v 돕다.v\n",
      "10756 지다.v 지니다.v\n",
      "10771 보다.v 비행하다.v\n",
      "10792 들다.v 듣다.v\n",
      "10817 균등하다.a 균등.n\n",
      "10824 균등하다.a 침해.n\n",
      "10837 이름.n 지어주다.v\n",
      "10841 놀라다.v 놀랍다.a\n",
      "10858 생각하다.v 위하다.v\n",
      "10870 수.n 수_있다.a\n",
      "10889 갈다.v 사러가다.v\n",
      "10893 내.n 화.n\n",
      "10899 갖다.v 대다.v\n",
      "10919 있다.a 수_있다.a\n",
      "10935 죽는소리하다.v 죽다.v\n",
      "10944 너무하다.a 너무.ad\n",
      "10951 속하다.v 들어가다.v\n",
      "10967 들다.v 듣다.v\n",
      "10992 걸다.a 걷다.v\n",
      "11013 해당.n 해당_단체.n\n",
      "11040 마다하다.v -마다.j\n",
      "11062 마음.n 속.n\n",
      "11073 튀다.v 오르다.v\n",
      "11077 갖다.v 대다.v\n",
      "11090 없다.a 수_있다.a\n",
      "11101 유동하다.v 유동화하다.v\n",
      "11107 걸다.a 걷다.v\n",
      "11109 수.n 수도.n\n",
      "11131 달리하다.v 달리.ad\n",
      "11137 있다.a 수_있다.a\n",
      "11150 있다.a 수_있다.a\n",
      "11151 있다.a 수_있다.a\n",
      "11155 있다.a 놓이다.v\n",
      "11170 들리다.v 들려주다.v\n",
      "11188 놀라다.v 놀랍다.a\n",
      "11192 화살n 화살.n\n",
      "11195 겨누다.V 겨누다.v\n",
      "11202 바다.n 해상.n\n",
      "11228 알리다.v 알려지다.v\n",
      "11229 쑥덕대다.v 쑥덕공론.n\n",
      "11233 되다.a 시작하다.v\n",
      "11247 들다.v 듣다.v\n",
      "11256 가지다.v 갖다.v\n",
      "11258 걸다.a 걷다.v\n",
      "11270 하다.a 할_말을_잃다.a\n",
      "11286 함께하다.v 함께.ad\n",
      "11298 주시.n 주다.v\n",
      "11309 대결하다.v 되다.a\n",
      "11334 달리기.n 달리다.v\n",
      "11357 축하받다.v 받다.v\n",
      "11374 봐주다.v 보다.v\n",
      "11376 대단하다.a 기뻐하다.v\n",
      "11396 함께하다.v 함께.ad\n",
      "11401 봐주다.v 보다.v\n",
      "11402 너무하다.a 너무.ad\n",
      "11403 답답하다.a 초조하다.a\n",
      "11418 안정되다.v 안정.n\n",
      "11485 썩다.v 골치가_아프다.v\n",
      "11493 갔다오다.v 가다.v\n",
      "11497 그리다.v 붙이다.v\n",
      "11518 못하다.a 가능하다.a\n",
      "11519 준하다.a 나오다.v\n",
      "11520 나다.v 낫다.v\n",
      "11527 더하다.a 덥다.a\n",
      "11536 지다.v 지니다.v\n",
      "11547 원하다.v 바람.n\n",
      "11560 찾다.v 없다.a\n",
      "11564 지다.v 지키다.v\n",
      "11588 수영.n 수영하다.v\n",
      "11592 오른쪽.n 우견.n\n",
      "11606 되다.a 괜찮다.a\n",
      "11618 없다.a 수_있다.a\n",
      "11630 말.n 말하다.v\n",
      "11632 마음.n 마음이_흐트러지다.v\n",
      "11634 가만있다.a 가만하다.v\n",
      "11654 하다.a 어이없다.a\n",
      "11661 에다.v 가운데.n\n",
      "11662 에다.v 가운데.n\n",
      "11710 들이다.v 들여다보다.v\n",
      "11721 있다.a 수_있다.a\n",
      "11733 하다.a 행하다.v\n",
      "11748 손.n 손쓰다.v\n",
      "11754 관리.n 망.n\n",
      "11763 보.n 보다.v\n",
      "11772 냄새.n 냄새나다.v\n",
      "11781 제조.n 제조하다.v\n",
      "11788 봐주다.v 보다.v\n",
      "11814 도착.n 도착하다.v\n",
      "11820 대서.n 대다.v\n",
      "11836 알다.v 조사하다.v\n",
      "11846 봐주다.v 보다.v\n",
      "11852 너무하다.a 너무.ad\n",
      "11860 일.n 활동.n\n",
      "11904 먹.n 기죽다.v\n",
      "11907 있다.a 수_있다.a\n",
      "11919 수.n 만하다.v\n",
      "11923 나다.v 나서다.v\n",
      "11925 나다.v 나아가다.v\n",
      "11928 손.n 손에_넣다.v\n",
      "11930 있다.a 수_있다.a\n",
      "11938 하다.a 움직이다.v\n",
      "11946 앉다.v 머무르다.v\n",
      "11947 앉다.v 멈추다.v\n",
      "11974 되다.a 오다.v\n",
      "11977 들다.v 듣다.v\n",
      "11978 들다.v 듣다.v\n",
      "11997 안다.v 알다.v\n",
      "12009 끼다.v 있다.a\n",
      "12044 진정하다.v 진정하다.a\n",
      "12055 갖다.v 하다.v\n",
      "12064 있다.a 생각하다.v\n",
      "12068 마음.n 아늑하다.a\n",
      "12091 아이들.n 어린이.n\n",
      "12092 잔소리듣다.v 잔소리를_듣다.v\n",
      "12105 보호받다.v 보호.n\n",
      "12143 시에프.n 짓다.v\n",
      "12149 취하하다.v 취하다.v\n",
      "12178 깜짝하다.v 놀라다.v\n",
      "12184 오다.v 이제와서.ad\n",
      "12200 만들다.v 창작하다.v\n",
      "12201 따라나서다.v 따라서.ad\n",
      "12205 나가다.v 팔리다.v\n",
      "12216 에다.v 사이.n\n",
      "12234 들다.v 들어주다.v\n",
      "12244 늘다.v 늘.ad\n",
      "12246 지다.v 지니다.v\n",
      "12257 죽는소리하다.v 죽다.v\n",
      "12264 있다.a 가지다.v\n",
      "12267 있다.a 수_있다.a\n",
      "12271 들다.v 듣다.v\n",
      "12301 부르다.v 부르짖다.v\n",
      "12309 따르다.v 가다.v\n",
      "12315 하다.a 명명하다.v\n",
      "12345 봐주다.v 보다.v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357 하다.a 수_있다.a\n",
      "12377 속.n 속마음.n\n",
      "12384 마을.n 마을_이름.n\n",
      "12387 깜짝하다.v 놀라다.v\n",
      "12397 사랑하다.v 사랑하는_자식.n\n",
      "12398 있다.a 가지다.v\n",
      "12430 있다.a 수_있다.a\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trn8)):\n",
    "    lu8 = get_lu(trn8[i][1])\n",
    "    lu1 = get_lu(trn1[i][1])\n",
    "    \n",
    "    if lu8 != lu1:\n",
    "        print(i, lu8, lu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['이것은', '서있는', '자세에서', '<tgt>', '타이핑', '되고', '</tgt>', '있다.'], ['_', '_', '_', '_', '타이핑되다.v', '타이핑되다.v', '_', '_'], ['_', '_', '_', '_', 'Text_creation', 'Text_creation', '_', '_'], ['B-Text', 'B-Depictive', 'I-Depictive', 'X', 'O', 'O', 'X', 'O']]\n",
      "\n",
      "[['이것은', '서있는', '자세에서', '<tgt>', '타이핑', '</tgt>', '되고', '있다.'], ['_', '_', '_', '_', '타이핑.n', '_', '_', '_'], ['_', '_', '_', '_', 'Text_creation', '_', '_', '_'], ['B-Text', 'B-Depictive', 'I-Depictive', 'X', 'O', 'X', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "n = 392\n",
    "\n",
    "print(trn8[n])\n",
    "print('')\n",
    "print(trn1[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = '/disk/frameBERT/model-kfn08/'\n",
    "# fnversion = '0.8'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)\n",
    "\n",
    "\n",
    "# model_dir = '/disk/frameBERT/model-kfn10/'\n",
    "# fnversion = '1.0'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trn=False, PRETRAINED_MODEL=\"bert-base-multilingual-cased\",\n",
    "          model_dir=False, epochs=20, fnversion=False):\n",
    "    print('\\tyour model would be saved at', model_dir)\n",
    "\n",
    "    # load a model first\n",
    "    model = BertForJointShallowSemanticParsing.from_pretrained(PRETRAINED_MODEL, \n",
    "                                                               num_senses = len(bert_io.sense2idx), \n",
    "                                                               num_args = len(bert_io.bio_arg2idx),\n",
    "                                                               lufrmap=bert_io.lufrmap, \n",
    "                                                               frargmap = bert_io.bio_frargmap)\n",
    "    model.to(device)\n",
    "    \n",
    "    trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "    sampler = RandomSampler(trn)\n",
    "    trn_dataloader = DataLoader(trn_data, sampler=sampler, batch_size=batch_size)\n",
    "    \n",
    "    # load optimizer\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "    \n",
    "    max_grad_norm = 1.0\n",
    "    num_of_epoch = 0\n",
    "    accuracy_result = []    \n",
    "    best_score = 0\n",
    "    \n",
    "    early_stopping = False\n",
    "    early_stopping = True\n",
    "    renew_stack = 0\n",
    "    \n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        \n",
    "        # TRAIN loop\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(trn_dataloader):\n",
    "            model.train()\n",
    "            # add batch to gpu\n",
    "            torch.cuda.set_device(device)\n",
    "#             torch.cuda.set_device(0)\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_orig_tok_to_maps, b_input_lus, b_input_senses, b_input_args, b_token_type_ids, b_input_masks = batch            \n",
    "            loss = model(b_input_ids, lus=b_input_lus, senses=b_input_senses, args=b_input_args,\n",
    "                     token_type_ids=b_token_type_ids, attention_mask=b_input_masks)\n",
    "            \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            \n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            \n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "    \n",
    "#             break\n",
    "\n",
    "        # save your model\n",
    "        model_saved_path = model_dir+str(num_of_epoch)+'/'\n",
    "        print('\\n\\tyour model is saved:', model_saved_path)\n",
    "        if not os.path.exists(model_saved_path):\n",
    "            os.makedirs(model_saved_path)\n",
    "        model.save_pretrained(model_saved_path)\n",
    "\n",
    "        num_of_epoch += 1\n",
    "        \n",
    "    print('...training is done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "with open('./data/frame_coreFE_list.json','r') as f:\n",
    "    frame_coreFE = json.load(f)\n",
    "\n",
    "def weighting(gold_frame, pred_frame, gold_args, pred_args):\n",
    "    \n",
    "    weighted_gold_frame, weighted_pred_frame = ['B-'+gold_frame], ['B-'+pred_frame]\n",
    "    weighted_gold_args, weighted_pred_args = gold_args.copy(), pred_args.copy()\n",
    "      \n",
    "    weighted_gold_frame.append('B-'+gold_frame)\n",
    "    weighted_pred_frame.append('B-'+pred_frame)        \n",
    "\n",
    "    for i in range(len(gold_args)):\n",
    "        gold_arg = gold_args[i]\n",
    "        pred_arg = pred_args[i]\n",
    "\n",
    "        fe = gold_arg.split('-')[-1]\n",
    "        if fe in frame_coreFE[gold_frame]:\n",
    "            weighted_gold_args.append(gold_arg)\n",
    "            weighted_pred_args.append(pred_arg)\n",
    "        elif fe == 'ARG':\n",
    "            weighted_gold_args.append(gold_arg)\n",
    "            weighted_pred_args.append(pred_arg)\n",
    "        else:\n",
    "            weighted_gold_args.append('O')\n",
    "            weighted_pred_args.append('O')\n",
    "        \n",
    "    return weighted_gold_frame, weighted_pred_frame, weighted_gold_args, weighted_pred_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(masking=True, model_path=False, tst_language='ko', trn_language='ko',\n",
    "         pretrained=\"bert-base-multilingual-cased\", mode='tst', fnversion=False, \n",
    "         result_dir=False):\n",
    "        \n",
    "    trn, dev, tst = dataio.load_data(srl=srl, language=tst_language, exem=False, info=False, fnversion=fnversion)\n",
    "    \n",
    "    \n",
    "    if mode == 'tst':\n",
    "        data = tst\n",
    "    else:\n",
    "        data = dev\n",
    "        \n",
    "    models = glob.glob(model_path+'*/')\n",
    "    eval_result = []\n",
    "    \n",
    "    fname = result_dir+'kfn'+str(fnversion)+'.txt'\n",
    "\n",
    "    tic()\n",
    "    for m in models:\n",
    "        print('### model dir:', m)\n",
    "        torch.cuda.set_device(device) \n",
    "        tst_model = frame_parser.FrameParser(gold_pred=True, model_path=m, viterbi=False, \n",
    "                                         fnversion=fnversion, masking=masking, language=trn_language, tgt=True,\n",
    "                                         pretrained=\"bert-base-multilingual-cased\", info=True)\n",
    "        \n",
    "        \n",
    "        gold_senses, pred_senses, gold_args, pred_args = [],[],[],[]        \n",
    "        gold_full_all, pred_full_all = [],[]        \n",
    "        \n",
    "        for instance in data:\n",
    "            torch.cuda.set_device(device)\n",
    "            result = tst_model.parser(instance)\n",
    "\n",
    "            gold_sense = [i for i in instance[2] if i != '_'][0]\n",
    "            pred_sense = [i for i in result[0][2] if i != '_'][0]\n",
    "\n",
    "            gold_arg = [i for i in instance[3] if i != 'X']\n",
    "            pred_arg = [i for i in result[0][3]]\n",
    "\n",
    "            gold_senses.append(gold_sense)\n",
    "            pred_senses.append(pred_sense)\n",
    "\n",
    "            weighted_gold_frame, weighted_pred_frame, weighted_gold_arg, weighted_pred_arg = weighting(gold_sense, pred_sense, gold_arg, pred_arg)\n",
    "\n",
    "            gold_args.append(weighted_gold_arg)\n",
    "            pred_args.append(weighted_pred_arg)            \n",
    "\n",
    "            gold_full = []\n",
    "            gold_full += weighted_gold_frame\n",
    "            gold_full += weighted_gold_arg\n",
    "\n",
    "            pred_full = []\n",
    "            pred_full += weighted_pred_frame\n",
    "            pred_full += weighted_pred_arg\n",
    "\n",
    "            gold_full_all.append(gold_full)\n",
    "            pred_full_all.append(pred_full)\n",
    "\n",
    "#             break\n",
    "\n",
    "        del tst_model\n",
    "\n",
    "        acc = accuracy_score(gold_senses, pred_senses)\n",
    "        arg_f1 = f1_score(gold_args, pred_args)\n",
    "        arg_precision = precision_score(gold_args, pred_args)\n",
    "        arg_recall = recall_score(gold_args, pred_args)\n",
    "        full_f1 = f1_score(gold_full_all, pred_full_all)\n",
    "        full_precision = precision_score(gold_full_all, pred_full_all)\n",
    "        full_recall = recall_score(gold_full_all, pred_full_all)\n",
    "        \n",
    "        epoch = m.split('/')[-2]\n",
    "        print('# EPOCH:', epoch)\n",
    "        print(\"SenseId Accuracy: {}\".format(acc))\n",
    "        print(\"ArgId Precision: {}\".format(arg_precision))\n",
    "        print(\"ArgId Recall: {}\".format(arg_recall))\n",
    "        print(\"ArgId F1: {}\".format(arg_f1))\n",
    "        print(\"full-structure Precision: {}\".format(full_precision))\n",
    "        print(\"full-structure Recall: {}\".format(full_recall))\n",
    "        print(\"full-structure F1: {}\".format(full_f1))\n",
    "        print('-----processing time:', tac())\n",
    "        print('')\n",
    "        \n",
    "        model_result = []\n",
    "        model_result.append(epoch)\n",
    "        model_result.append(acc)\n",
    "        model_result.append(arg_precision)\n",
    "        model_result.append(arg_recall)\n",
    "        model_result.append(arg_f1)\n",
    "#         if 'framenet' in srl:\n",
    "        model_result.append(full_precision)\n",
    "        model_result.append(full_recall)\n",
    "        model_result.append(full_f1)\n",
    "        model_result = [str(i) for i in model_result]\n",
    "        eval_result.append(model_result)\n",
    "        \n",
    "    with open(fname,'w') as f:\n",
    "        f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\t'+'full_P'+'\\t'+'full_R'+'\\t'+'full_F1'+'\\n')\n",
    "        for i in eval_result:\n",
    "            line = '\\t'.join(i)\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "        print('\\n\\t### Your result is saved at:', fname)\n",
    "        print('...done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### TRAINING\n",
      "MODEL: framenet\n",
      "PRETRAINED BERT: bert-base-multilingual-cased\n",
      "BATCH_SIZE: 6\n",
      "MAX_LEN: 256\n",
      "epochs: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "epochs = 20\n",
    "masking = True\n",
    "MAX_LEN = 256\n",
    "batch_size = 6\n",
    "PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "print('')\n",
    "print('### TRAINING')\n",
    "print('MODEL:', srl)\n",
    "print('PRETRAINED BERT:', PRETRAINED_MODEL)\n",
    "print('BATCH_SIZE:', batch_size)\n",
    "print('MAX_LEN:', MAX_LEN)\n",
    "print('epochs:', epochs)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "\n",
      "### loading Korean FrameNet 0.8 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/frameBERT/model-kfn08/'\n",
    "# fnversion = '0.8'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)\n",
    "\n",
    "# train(trn=trn, epochs=epochs, model_dir=model_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn1.0_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn1.0_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "\n",
      "### loading Korean FrameNet 1.0 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/frameBERT/model-kfn10/'\n",
    "# fnversion = '1.0'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)\n",
    "\n",
    "# train(trn=trn, epochs=epochs, model_dir=model_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model dir: /disk/frameBERT/model-kfn08/3/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/3/\n",
      "/disk/frameBERT/model-kfn08/3/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 3\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:4sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/15/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/15/\n",
      "/disk/frameBERT/model-kfn08/15/\n",
      "...model is loaded\n",
      "# EPOCH: 15\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:9sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/12/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/12/\n",
      "/disk/frameBERT/model-kfn08/12/\n",
      "...model is loaded\n",
      "# EPOCH: 12\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:13sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/1/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/1/\n",
      "/disk/frameBERT/model-kfn08/1/\n",
      "...model is loaded\n",
      "# EPOCH: 1\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0.0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 0.1111111111111111\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.13333333333333333\n",
      "-----processing time: 0hour:0min:20sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/11/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/11/\n",
      "/disk/frameBERT/model-kfn08/11/\n",
      "...model is loaded\n",
      "# EPOCH: 11\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:25sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/2/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/2/\n",
      "/disk/frameBERT/model-kfn08/2/\n",
      "...model is loaded\n",
      "# EPOCH: 2\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:32sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/4/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/4/\n",
      "/disk/frameBERT/model-kfn08/4/\n",
      "...model is loaded\n",
      "# EPOCH: 4\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:40sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/9/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/9/\n",
      "/disk/frameBERT/model-kfn08/9/\n",
      "...model is loaded\n",
      "# EPOCH: 9\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:47sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/17/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/17/\n",
      "/disk/frameBERT/model-kfn08/17/\n",
      "...model is loaded\n",
      "# EPOCH: 17\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:51sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/10/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/10/\n",
      "/disk/frameBERT/model-kfn08/10/\n",
      "...model is loaded\n",
      "# EPOCH: 10\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:59sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/8/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/8/\n",
      "/disk/frameBERT/model-kfn08/8/\n",
      "...model is loaded\n",
      "# EPOCH: 8\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:7sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/0/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loaded model path: /disk/frameBERT/model-kfn08/0/\n",
      "/disk/frameBERT/model-kfn08/0/\n",
      "...model is loaded\n",
      "# EPOCH: 0\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0.0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 0.05\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.07692307692307691\n",
      "-----processing time: 0hour:1min:14sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/6/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/6/\n",
      "/disk/frameBERT/model-kfn08/6/\n",
      "...model is loaded\n",
      "# EPOCH: 6\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:22sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/7/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/7/\n",
      "/disk/frameBERT/model-kfn08/7/\n",
      "...model is loaded\n",
      "# EPOCH: 7\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:29sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/13/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/13/\n",
      "/disk/frameBERT/model-kfn08/13/\n",
      "...model is loaded\n",
      "# EPOCH: 13\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:37sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/16/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/16/\n",
      "/disk/frameBERT/model-kfn08/16/\n",
      "...model is loaded\n",
      "# EPOCH: 16\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:45sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/dummy/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/dummy/\n",
      "/disk/frameBERT/model-kfn08/dummy/\n",
      "...model is loaded\n",
      "# EPOCH: dummy\n",
      "SenseId Accuracy: 1.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:49sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/19/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/19/\n",
      "/disk/frameBERT/model-kfn08/19/\n",
      "...model is loaded\n",
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:56sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/5/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/5/\n",
      "/disk/frameBERT/model-kfn08/5/\n",
      "...model is loaded\n",
      "# EPOCH: 5\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:4sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/18/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/18/\n",
      "/disk/frameBERT/model-kfn08/18/\n",
      "...model is loaded\n",
      "# EPOCH: 18\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:12sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/14/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/14/\n",
      "/disk/frameBERT/model-kfn08/14/\n",
      "...model is loaded\n",
      "# EPOCH: 14\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:20sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/frameBERT/eval_result/kfn0.8.txt\n",
      "...done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_path = '/disk/frameBERT/model-kfn08/'\n",
    "# result_dir = '/disk/frameBERT/eval_result/'\n",
    "# fnversion = '0.8'\n",
    "\n",
    "# test(model_path=model_path, result_dir=result_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/disk/frameBERT/model-kfn10/'\n",
    "result_dir = '/disk/frameBERT/eval_result/'\n",
    "fnversion = '1.0'\n",
    "\n",
    "test(model_path=model_path, result_dir=result_dir, fnversion=fnversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
