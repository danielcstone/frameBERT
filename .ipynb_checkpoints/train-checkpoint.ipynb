{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from transformers import *\n",
    "from frameBERT.src import utils\n",
    "from frameBERT.src import dataio\n",
    "from frameBERT import frame_parser\n",
    "from frameBERT.src.modeling import BertForJointShallowSemanticParsing\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if device != \"cpu\":\n",
    "    torch.cuda.set_device(0)\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)   \n",
    "random.seed(0)\n",
    "\n",
    "from torch import autograd\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행시간 측정 함수\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60)\n",
    "    \n",
    "    result = '{}hour:{}min:{}sec'.format(t_hour,t_min,t_sec)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trn=False, PRETRAINED_MODEL=\"bert-base-multilingual-cased\",\n",
    "          model_dir=False, epochs=20, fnversion=False):\n",
    "    print('\\tyour model would be saved at', model_dir)\n",
    "\n",
    "    # load a model first\n",
    "    model = BertForJointShallowSemanticParsing.from_pretrained(PRETRAINED_MODEL, \n",
    "                                                               num_senses = len(bert_io.sense2idx), \n",
    "                                                               num_args = len(bert_io.bio_arg2idx),\n",
    "                                                               lufrmap=bert_io.lufrmap, \n",
    "                                                               frargmap = bert_io.bio_frargmap)\n",
    "    model.to(device)\n",
    "    \n",
    "    trn_data = bert_io.convert_to_bert_input_JointShallowSemanticParsing(trn)\n",
    "    sampler = RandomSampler(trn)\n",
    "    trn_dataloader = DataLoader(trn_data, sampler=sampler, batch_size=batch_size)\n",
    "    \n",
    "    # load optimizer\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "    \n",
    "    max_grad_norm = 1.0\n",
    "    num_of_epoch = 0\n",
    "    accuracy_result = []    \n",
    "    best_score = 0\n",
    "    \n",
    "    early_stopping = False\n",
    "    early_stopping = True\n",
    "    renew_stack = 0\n",
    "    \n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        \n",
    "        # TRAIN loop\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(trn_dataloader):\n",
    "            model.train()\n",
    "            # add batch to gpu\n",
    "            torch.cuda.set_device(device)\n",
    "#             torch.cuda.set_device(0)\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_orig_tok_to_maps, b_input_lus, b_input_senses, b_input_args, b_token_type_ids, b_input_masks = batch            \n",
    "            loss = model(b_input_ids, lus=b_input_lus, senses=b_input_senses, args=b_input_args,\n",
    "                     token_type_ids=b_token_type_ids, attention_mask=b_input_masks)\n",
    "            \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            \n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            \n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "    \n",
    "#             break\n",
    "\n",
    "        # save your model\n",
    "        model_saved_path = model_dir+str(num_of_epoch)+'/'\n",
    "        print('\\n\\tyour model is saved:', model_saved_path)\n",
    "        if not os.path.exists(model_saved_path):\n",
    "            os.makedirs(model_saved_path)\n",
    "        model.save_pretrained(model_saved_path)\n",
    "\n",
    "        num_of_epoch += 1\n",
    "        \n",
    "    print('...training is done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "with open('./data/frame_coreFE_list.json','r') as f:\n",
    "    frame_coreFE = json.load(f)\n",
    "\n",
    "def weighting(gold_frame, pred_frame, gold_args, pred_args):\n",
    "    \n",
    "    weighted_gold_frame, weighted_pred_frame = ['B-'+gold_frame], ['B-'+pred_frame]\n",
    "    weighted_gold_args, weighted_pred_args = gold_args.copy(), pred_args.copy()\n",
    "      \n",
    "    weighted_gold_frame.append('B-'+gold_frame)\n",
    "    weighted_pred_frame.append('B-'+pred_frame)        \n",
    "\n",
    "    for i in range(len(gold_args)):\n",
    "        gold_arg = gold_args[i]\n",
    "        pred_arg = pred_args[i]\n",
    "\n",
    "        fe = gold_arg.split('-')[-1]\n",
    "        if fe in frame_coreFE[gold_frame]:\n",
    "            weighted_gold_args.append(gold_arg)\n",
    "            weighted_pred_args.append(pred_arg)\n",
    "        elif fe == 'ARG':\n",
    "            weighted_gold_args.append(gold_arg)\n",
    "            weighted_pred_args.append(pred_arg)\n",
    "        else:\n",
    "            weighted_gold_args.append('O')\n",
    "            weighted_pred_args.append('O')\n",
    "        \n",
    "    return weighted_gold_frame, weighted_pred_frame, weighted_gold_args, weighted_pred_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(masking=True, model_path=False, tst_language='ko', trn_language='ko',\n",
    "         pretrained=\"bert-base-multilingual-cased\", mode='tst', fnversion=False, \n",
    "         result_dir=False):\n",
    "        \n",
    "    trn, dev, tst = dataio.load_data(srl=srl, language=tst_language, exem=False, info=False, fnversion=fnversion)\n",
    "    \n",
    "    \n",
    "    if mode == 'tst':\n",
    "        data = tst\n",
    "    else:\n",
    "        data = dev\n",
    "        \n",
    "    models = glob.glob(model_path+'*/')\n",
    "    eval_result = []\n",
    "    \n",
    "    fname = result_dir+'kfn'+str(fnversion)+'.txt'\n",
    "\n",
    "    tic()\n",
    "    for m in models:\n",
    "        print('### model dir:', m)\n",
    "        torch.cuda.set_device(device) \n",
    "        tst_model = frame_parser.FrameParser(gold_pred=True, model_path=m, viterbi=False, \n",
    "                                         fnversion=fnversion, masking=masking, language=trn_language, tgt=True,\n",
    "                                         pretrained=\"bert-base-multilingual-cased\", info=True)\n",
    "        \n",
    "        \n",
    "        gold_senses, pred_senses, gold_args, pred_args = [],[],[],[]        \n",
    "        gold_full_all, pred_full_all = [],[]        \n",
    "        \n",
    "        for instance in data:\n",
    "            torch.cuda.set_device(device)\n",
    "            result = tst_model.parser(instance)\n",
    "\n",
    "            gold_sense = [i for i in instance[2] if i != '_'][0]\n",
    "            pred_sense = [i for i in result[0][2] if i != '_'][0]\n",
    "\n",
    "            gold_arg = [i for i in instance[3] if i != 'X']\n",
    "            pred_arg = [i for i in result[0][3]]\n",
    "\n",
    "            gold_senses.append(gold_sense)\n",
    "            pred_senses.append(pred_sense)\n",
    "\n",
    "            weighted_gold_frame, weighted_pred_frame, weighted_gold_arg, weighted_pred_arg = weighting(gold_sense, pred_sense, gold_arg, pred_arg)\n",
    "\n",
    "            gold_args.append(weighted_gold_arg)\n",
    "            pred_args.append(weighted_pred_arg)            \n",
    "\n",
    "            gold_full = []\n",
    "            gold_full += weighted_gold_frame\n",
    "            gold_full += weighted_gold_arg\n",
    "\n",
    "            pred_full = []\n",
    "            pred_full += weighted_pred_frame\n",
    "            pred_full += weighted_pred_arg\n",
    "\n",
    "            gold_full_all.append(gold_full)\n",
    "            pred_full_all.append(pred_full)\n",
    "\n",
    "#             break\n",
    "\n",
    "        del tst_model\n",
    "\n",
    "        acc = accuracy_score(gold_senses, pred_senses)\n",
    "        arg_f1 = f1_score(gold_args, pred_args)\n",
    "        arg_precision = precision_score(gold_args, pred_args)\n",
    "        arg_recall = recall_score(gold_args, pred_args)\n",
    "        full_f1 = f1_score(gold_full_all, pred_full_all)\n",
    "        full_precision = precision_score(gold_full_all, pred_full_all)\n",
    "        full_recall = recall_score(gold_full_all, pred_full_all)\n",
    "        \n",
    "        epoch = m.split('/')[-2]\n",
    "        print('# EPOCH:', epoch)\n",
    "        print(\"SenseId Accuracy: {}\".format(acc))\n",
    "        print(\"ArgId Precision: {}\".format(arg_precision))\n",
    "        print(\"ArgId Recall: {}\".format(arg_recall))\n",
    "        print(\"ArgId F1: {}\".format(arg_f1))\n",
    "        print(\"full-structure Precision: {}\".format(full_precision))\n",
    "        print(\"full-structure Recall: {}\".format(full_recall))\n",
    "        print(\"full-structure F1: {}\".format(full_f1))\n",
    "        print('-----processing time:', tac())\n",
    "        print('')\n",
    "        \n",
    "        model_result = []\n",
    "        model_result.append(epoch)\n",
    "        model_result.append(acc)\n",
    "        model_result.append(arg_precision)\n",
    "        model_result.append(arg_recall)\n",
    "        model_result.append(arg_f1)\n",
    "#         if 'framenet' in srl:\n",
    "        model_result.append(full_precision)\n",
    "        model_result.append(full_recall)\n",
    "        model_result.append(full_f1)\n",
    "        model_result = [str(i) for i in model_result]\n",
    "        eval_result.append(model_result)\n",
    "        \n",
    "    with open(fname,'w') as f:\n",
    "        f.write('epoch'+'\\t''SenseID'+'\\t'+'Arg_P'+'\\t'+'Arg_R'+'\\t'+'ArgF1'+'\\t'+'full_P'+'\\t'+'full_R'+'\\t'+'full_F1'+'\\n')\n",
    "        for i in eval_result:\n",
    "            line = '\\t'.join(i)\n",
    "            f.write(line+'\\n')\n",
    "            \n",
    "        print('\\n\\t### Your result is saved at:', fname)\n",
    "        print('...done\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### TRAINING\n",
      "MODEL: framenet\n",
      "PRETRAINED BERT: bert-base-multilingual-cased\n",
      "BATCH_SIZE: 6\n",
      "MAX_LEN: 256\n",
      "epochs: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srl = 'framenet'\n",
    "epochs = 20\n",
    "masking = True\n",
    "MAX_LEN = 256\n",
    "batch_size = 6\n",
    "PRETRAINED_MODEL = \"bert-base-multilingual-cased\"\n",
    "print('')\n",
    "print('### TRAINING')\n",
    "print('MODEL:', srl)\n",
    "print('PRETRAINED BERT:', PRETRAINED_MODEL)\n",
    "print('BATCH_SIZE:', batch_size)\n",
    "print('MAX_LEN:', MAX_LEN)\n",
    "print('epochs:', epochs)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "\n",
      "### loading Korean FrameNet 0.8 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/frameBERT/model-kfn08/'\n",
    "# fnversion = '0.8'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)\n",
    "\n",
    "# train(trn=trn, epochs=epochs, model_dir=model_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn1.0_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn1.0_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "\n",
      "### loading Korean FrameNet 1.0 data...\n",
      "\t# of instances in training data: 12431\n",
      "\t# of instances in dev data: 624\n",
      "\t# of instances in test data: 4382\n"
     ]
    }
   ],
   "source": [
    "# model_dir = '/disk/frameBERT/model-kfn10/'\n",
    "# fnversion = '1.0'\n",
    "# language = 'ko'\n",
    "# bert_io = utils.for_BERT(mode='train', language=language, masking=True, fnversion=fnversion)\n",
    "# trn, dev, tst = dataio.load_data(srl=srl, language=language, fnversion=fnversion)\n",
    "\n",
    "# train(trn=trn, epochs=epochs, model_dir=model_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### model dir: /disk/frameBERT/model-kfn08/3/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/3/\n",
      "/disk/frameBERT/model-kfn08/3/\n",
      "...model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../frameBERT/src/utils.py:279: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_logits = sm(masked_logit).view(1,-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH: 3\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:4sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/15/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/15/\n",
      "/disk/frameBERT/model-kfn08/15/\n",
      "...model is loaded\n",
      "# EPOCH: 15\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:9sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/12/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/12/\n",
      "/disk/frameBERT/model-kfn08/12/\n",
      "...model is loaded\n",
      "# EPOCH: 12\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:13sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/1/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/1/\n",
      "/disk/frameBERT/model-kfn08/1/\n",
      "...model is loaded\n",
      "# EPOCH: 1\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0.0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 0.1111111111111111\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.13333333333333333\n",
      "-----processing time: 0hour:0min:20sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/11/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/11/\n",
      "/disk/frameBERT/model-kfn08/11/\n",
      "...model is loaded\n",
      "# EPOCH: 11\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:25sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/2/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/2/\n",
      "/disk/frameBERT/model-kfn08/2/\n",
      "...model is loaded\n",
      "# EPOCH: 2\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:32sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/4/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/4/\n",
      "/disk/frameBERT/model-kfn08/4/\n",
      "...model is loaded\n",
      "# EPOCH: 4\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:40sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/9/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/9/\n",
      "/disk/frameBERT/model-kfn08/9/\n",
      "...model is loaded\n",
      "# EPOCH: 9\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:47sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/17/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/17/\n",
      "/disk/frameBERT/model-kfn08/17/\n",
      "...model is loaded\n",
      "# EPOCH: 17\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:51sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/10/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/10/\n",
      "/disk/frameBERT/model-kfn08/10/\n",
      "...model is loaded\n",
      "# EPOCH: 10\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:0min:59sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/8/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/8/\n",
      "/disk/frameBERT/model-kfn08/8/\n",
      "...model is loaded\n",
      "# EPOCH: 8\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:7sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/0/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loaded model path: /disk/frameBERT/model-kfn08/0/\n",
      "/disk/frameBERT/model-kfn08/0/\n",
      "...model is loaded\n",
      "# EPOCH: 0\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0.0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 0.05\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.07692307692307691\n",
      "-----processing time: 0hour:1min:14sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/6/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/6/\n",
      "/disk/frameBERT/model-kfn08/6/\n",
      "...model is loaded\n",
      "# EPOCH: 6\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:22sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/7/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/7/\n",
      "/disk/frameBERT/model-kfn08/7/\n",
      "...model is loaded\n",
      "# EPOCH: 7\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:29sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/13/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/13/\n",
      "/disk/frameBERT/model-kfn08/13/\n",
      "...model is loaded\n",
      "# EPOCH: 13\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:37sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/16/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/16/\n",
      "/disk/frameBERT/model-kfn08/16/\n",
      "...model is loaded\n",
      "# EPOCH: 16\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:45sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/dummy/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/dummy/\n",
      "/disk/frameBERT/model-kfn08/dummy/\n",
      "...model is loaded\n",
      "# EPOCH: dummy\n",
      "SenseId Accuracy: 1.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:49sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/19/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/19/\n",
      "/disk/frameBERT/model-kfn08/19/\n",
      "...model is loaded\n",
      "# EPOCH: 19\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:1min:56sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/5/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/5/\n",
      "/disk/frameBERT/model-kfn08/5/\n",
      "...model is loaded\n",
      "# EPOCH: 5\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:4sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/18/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/18/\n",
      "/disk/frameBERT/model-kfn08/18/\n",
      "...model is loaded\n",
      "# EPOCH: 18\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:12sec\n",
      "\n",
      "### model dir: /disk/frameBERT/model-kfn08/14/\n",
      "srl model: framenet\n",
      "language: ko\n",
      "version: 0.8\n",
      "using viterbi: False\n",
      "using masking: True\n",
      "pretrained BERT: bert-base-multilingual-cased\n",
      "using TGT special token: True\n",
      "used dictionary:\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lu2idx.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/kfn0.8_lufrmap.json\n",
      "\t /disk/frameBERT/frameBERT/src/../koreanframenet/resource/info/mul_bio_frargmap.json\n",
      "...loaded model path: /disk/frameBERT/model-kfn08/14/\n",
      "/disk/frameBERT/model-kfn08/14/\n",
      "...model is loaded\n",
      "# EPOCH: 14\n",
      "SenseId Accuracy: 0.0\n",
      "ArgId Precision: 0\n",
      "ArgId Recall: 0.0\n",
      "ArgId F1: 0\n",
      "full-structure Precision: 1.0\n",
      "full-structure Recall: 0.16666666666666666\n",
      "full-structure F1: 0.2857142857142857\n",
      "-----processing time: 0hour:2min:20sec\n",
      "\n",
      "\n",
      "\t### Your result is saved at: /disk/frameBERT/eval_result/kfn0.8.txt\n",
      "...done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_path = '/disk/frameBERT/model-kfn08/'\n",
    "# result_dir = '/disk/frameBERT/eval_result/'\n",
    "# fnversion = '0.8'\n",
    "\n",
    "# test(model_path=model_path, result_dir=result_dir, fnversion=fnversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/disk/frameBERT/model-kfn10/'\n",
    "result_dir = '/disk/frameBERT/eval_result/'\n",
    "fnversion = '1.0'\n",
    "\n",
    "test(model_path=model_path, result_dir=result_dir, fnversion=fnversion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
